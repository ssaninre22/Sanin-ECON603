fill  = "",linetype="",
#title = "Unemployment in college vs non-college counties",
subtitle = "Median (line) with 25th–75th percentiles shaded"
) +
theme_bw(base_size = 16)+theme(legend.position=c(.2,.75))+
labs(x="")+
scale_x_date(date_breaks = "4 years",date_labels = "%Y")
ggsave(filename = "output/g1msa.png",g1msa,scale=1,units = "cm",width = 20,height=15)
recessdf <- read_excel("data/macro/USRECM.xlsx",sheet=2) %>%
mutate(date = as.Date(date,format="%Y-%m-%d"))
df_msas2 <- df_msas2 %>% merge(recessdf,by="date",all.x = T) %>%
mutate(month_fe = factor(format(date, "%m")))
library(fixest)
did_mod <- feols(
value_sa ~ CTind * USRECM | msa_fips + date,
cluster = ~ msa_fips,
data = df_msas2 %>% dplyr::filter(year<2020)
)
summary(did_mod)
# Event
# Identify recession start months (from peak→trough indicator)
df2 <- df_msas2 %>%
mutate(
# ensure Date class; your format is "%Y-%m-%d"
date = as.Date(date, format = "%Y-%m-%d")
)
# Create a global time index t = 1, 2, 3, ... for each unique date
time_index <- df2 %>%
distinct(date) %>%
arrange(date) %>%
mutate(t = row_number())
# Join back to your main data
df2 <- df2 %>%
left_join(time_index, by = "date") %>%
arrange(msa_fips, date)
# Recession info by date (USRECM should be same for all counties each date)
rec_info <- df2 %>%
distinct(date, t, USRECM) %>%
arrange(t)
# A recession starts when USRECM goes from 0 -> 1
rec_info <- rec_info %>%
mutate(rec_start = ifelse(USRECM == 1 & dplyr::lag(USRECM, default = 0) == 0, 1, 0))
# Vector of t indices where recessions start
rec_start_t <- rec_info %>%
filter(rec_start == 1) %>%
pull(t)
rec_start_t
if (length(rec_start_t) == 0) {
stop("No recession starts found (USRECM never goes 0 -> 1).")
}
# Function that gives distance (in periods) to nearest recession start
closest_rel_time <- function(t, rec_starts) {
# rec_starts is the vector rec_start_t
diffs <- t - rec_starts
diffs[which.min(abs(diffs))]
}
# Compute rel_time for each row
df2$rel_time <- vapply(df2$t, closest_rel_time, integer(1L),
rec_starts = rec_start_t)
# Trim / bin the event window and pick a valid reference period
min_k <- -24
max_k <-  24
df2 <- df2 %>%
mutate(
rel_group = case_when(
rel_time < min_k ~ min_k,
rel_time > max_k ~ max_k,
TRUE ~ rel_time
)
)
# Check what values you actually have
sort(unique(df2$rel_group))
# last pre-recession event period present (e.g. -1, -2, etc.)
base_period <- max(df2$rel_group[df2$rel_group < 0], na.rm = TRUE)
base_period
# Run the event-study regression (fixest)
event_est <- feols(
value_sa ~ i(rel_group, CTind, ref = base_period) | msa_fips + t,
cluster = ~ msa_fips,
data = df2 %>% dplyr::filter(year<2020)
)
summary(event_est)
g2msa_event <- ggiplot(event_est)+
labs(
#title = "Event Study: Effect of Recessions on Unemployment in College Towns",
title="",subtitle = "Estimation by MSAs",
x = "Periods relative to recession start",
y = "Effect on unemployment rate (percentage points)")+theme_bw(base_size = 16)
ggsave(filename = "output/g2msa.png",g2msa_event,scale=1,units = "cm",width = 20,height=15)
# Run the event-study regression (fixest)
event_est <- feols(
value_sa ~ i(rel_group, CTind, ref = base_period) | county_fips + t,
cluster = ~ county_fips,
data = df2
)
df_counties <- ds_month %>%
filter(
measure_code == "03",
area_type_code == "F",
year >= 1990, year <= 2025
) %>%
{ if (is.null(seasonal_pref)) . else filter(., seasonal_code == seasonal_pref) } %>%
mutate(
date  = as.Date(paste0(year,"-", month, "-01"),format="%Y-%m-%d"),
value = cast(value, float64(), safe = FALSE)
) %>%
collect()
df_counties <- df_counties %>%
mutate(
state_fips  = as.integer(substr(area_code, 3, 4)),
county_fips = as.integer(substr(area_code, 3, 7))
) %>%
mutate(county_fips = as.character(county_fips))
ctowns2 <- ctowns %>%
mutate(FIPS_county = as.character(FIPS_county)) %>%
distinct(FIPS_county) %>%
mutate(CTind = 1)
df_counties2 <- df_counties %>%
left_join(ctowns2, by = c("county_fips" = "FIPS_county")) %>%
mutate(
CTind = ifelse(is.na(CTind),0, 1)
)
# SA Data
library(feasts)    # for STL decomposition with tsibble
library(tsibble)
library(imputeTS)   # for robust interpolation of missing values
df_ts <- df_counties2 %>%
mutate(
date = yearmonth(date)  # from lubridate & tsibble
) %>%
as_tsibble(
key = county_fips,
index = date
)
df_ts <- df_ts %>%
group_by(county_fips) %>%
mutate(
value_interp = na_interpolation(value, option = "linear")
) %>%
ungroup()
df_stl <- df_ts %>%
model(STL(value_interp ~ season(window = "periodic"))) %>%
components() %>%
mutate(
# seasonally adjusted = observed - seasonal
value_sa = season_adjust
) %>%
as_tibble()
df_counties2 <- df_counties2 %>%
mutate(date = yearmonth(as.Date(date))) %>%
left_join(df_stl %>% select(county_fips, date, value_sa),
by = c("county_fips", "date"))
df_counties2 <- df_counties2 %>%
mutate(date = as.Date(date))
ggplot(df_counties2, aes(x = date, y = value_sa, group = county_fips)) +
# background: all counties in grey
geom_line(color = "grey80", alpha = 0.4) +
# highlight: college towns in black
geom_line(
data = df_counties2 %>% dplyr::filter(CTind == 1),
color = "black",
alpha = 0.9,
linewidth  = 0.6
) +
labs(
x = "Date",
y = "Unemployment rate",
title = "Unemployment time series: all counties (grey) vs college towns (black)"
) +
theme_minimal()
# 1. Summarise by date and college_town
df_summary <- df_counties2 %>%
group_by(date, CTind) %>%
summarise(
p25 = quantile(value_sa, 0.25, na.rm = TRUE),
p50 = quantile(value_sa, 0.50, na.rm = TRUE),
p75 = quantile(value_sa, 0.75, na.rm = TRUE),
.groups = "drop"
) %>%
mutate(
CTind = factor(
CTind,
levels = c(0, 1),
labels = c("Non-college counties", "College-town counties")
)
)
# 2. Plot: ribbon = IQR, line = median
g1county <- ggplot(df_summary,
aes(x = date)) +
geom_ribbon(aes(ymin = p25, ymax = p75,
color = CTind,
fill  = CTind),
alpha = 0.20,
color = NA) +
geom_line(aes(y = p50,linetype = CTind,color = CTind),
size = 1) +
scale_linetype_manual(values = c("dotted","solid"),
labels=c('Non-college counties', 'College-town counties'))+
labs(
x = "Date",
y = "Unemployment rate",
color = "",
fill  = "",linetype="",
#title = "Unemployment in college vs non-college counties",
subtitle = "Median (line) with 25th–75th percentiles shaded"
) +
theme_bw(base_size = 16)+theme(legend.position=c(.2,.75))+
labs(x="")+
scale_x_date(date_breaks = "4 years",date_labels = "%Y")
ggsave(filename = "output/g1county.png",g1county,scale=1,units = "cm",width = 20,height=15)
recessdf <- read_excel("data/macro/USRECM.xlsx",sheet=2) %>%
mutate(date = as.Date(date,format="%Y-%m-%d"))
df_counties2 <- df_counties2 %>% merge(recessdf,by="date",all.x = T) %>%
mutate(month_fe = factor(format(date, "%m")))
library(fixest)
did_mod <- feols(
value_sa ~ CTind * USRECM | county_fips + date,
cluster = ~ county_fips,
data = df_counties2
)
summary(did_mod)
# Event
# Identify recession start months (from peak→trough indicator)
df2 <- df_counties2 %>%
mutate(
# ensure Date class; your format is "%Y-%m-%d"
date = as.Date(date, format = "%Y-%m-%d")
)
# Create a global time index t = 1, 2, 3, ... for each unique date
time_index <- df2 %>%
distinct(date) %>%
arrange(date) %>%
mutate(t = row_number())
# Join back to your main data
df2 <- df2 %>%
left_join(time_index, by = "date") %>%
arrange(county_fips, date)
# Recession info by date (USRECM should be same for all counties each date)
rec_info <- df2 %>%
distinct(date, t, USRECM) %>%
arrange(t)
# A recession starts when USRECM goes from 0 -> 1
rec_info <- rec_info %>%
mutate(rec_start = ifelse(USRECM == 1 & dplyr::lag(USRECM, default = 0) == 0, 1, 0))
# Vector of t indices where recessions start
rec_start_t <- rec_info %>%
filter(rec_start == 1) %>%
pull(t)
rec_start_t
if (length(rec_start_t) == 0) {
stop("No recession starts found (USRECM never goes 0 -> 1).")
}
# Function that gives distance (in periods) to nearest recession start
closest_rel_time <- function(t, rec_starts) {
# rec_starts is the vector rec_start_t
diffs <- t - rec_starts
diffs[which.min(abs(diffs))]
}
# Compute rel_time for each row
df2$rel_time <- vapply(df2$t, closest_rel_time, integer(1L),
rec_starts = rec_start_t)
# Trim / bin the event window and pick a valid reference period
min_k <- -24
max_k <-  24
df2 <- df2 %>%
mutate(
rel_group = case_when(
rel_time < min_k ~ min_k,
rel_time > max_k ~ max_k,
TRUE ~ rel_time
)
)
# Check what values you actually have
sort(unique(df2$rel_group))
# last pre-recession event period present (e.g. -1, -2, etc.)
base_period <- max(df2$rel_group[df2$rel_group < 0], na.rm = TRUE)
base_period
# Run the event-study regression (fixest)
event_est <- feols(
value_sa ~ i(rel_group, CTind, ref = base_period) | county_fips + t,
cluster = ~ county_fips,
data = df2
)
summary(event_est)
g2county_all <- ggiplot(event_est)+
labs(
#title = "Event Study: Effect of Recessions on Unemployment in College Towns",
title="",subtitle = "Estimation by county",
x = "Periods relative to recession start",
y = "Effect on unemployment rate (percentage points)")+theme_bw(base_size = 16)
ggsave(filename = "output/g2county.png",g2county_all,scale=1,units = "cm",width = 20,height=15)
# Run the event-study regression (fixest) without COVID
event_est <- feols(
value_sa ~ i(rel_group, CTind, ref = base_period) | county_fips + t,
cluster = ~ county_fips,
data = df2 %>% filter(year<2020)
)
summary(event_est)
g2county_pre <- ggiplot(event_est)+
labs(
#title = "Event Study: Effect of Recessions on Unemployment in College Towns",
title="",subtitle = "Estimation by county",
x = "Periods relative to recession start",
y = "Effect on unemployment rate (percentage points)")+theme_bw(base_size = 16)
ggsave(filename = "output/g2county_pre.png",g2county_pre,scale=1,units = "cm",width = 20,height=15)
df_msas <- ds_month %>%
filter(
measure_code == "03",
area_type_code == "B",
year >= 1990, year <= 2025
) %>%
{ if (is.null(seasonal_pref)) . else filter(., seasonal_code == seasonal_pref) } %>%
mutate(
date  = as.Date(paste0(year,"-", month, "-01"),format="%Y-%m-%d"),
value = cast(value, float64(), safe = FALSE)
) %>%
collect()
df_msas <- df_msas %>%
mutate(
state_fips  = as.integer(substr(area_code, 3, 4)),
msa_fips = as.integer(substr(area_code, 5, 9))
) %>%
mutate(msa_fips = as.character(msa_fips))
ctowns2 <- ctowns %>%
mutate(FIPS_MSA = as.character(FIPS_MSA)) %>%
distinct(FIPS_MSA) %>%
mutate(CTind = 1)
df_msas2 <- df_msas %>%
left_join(ctowns2, by = c("msa_fips" = "FIPS_MSA")) %>%
mutate(
CTind = ifelse(is.na(CTind),0, 1)
)
df_ts <- df_msas2 %>%
mutate(
date = yearmonth(date)  # from lubridate & tsibble
) %>%
as_tsibble(
key = msa_fips,
index = date
)
df_ts <- df_ts %>%
group_by(msa_fips) %>%
mutate(
value_interp = na_interpolation(value, option = "linear")
) %>%
ungroup()
df_stl <- df_ts %>%
model(STL(value_interp ~ season(window = "periodic"))) %>%
components() %>%
mutate(
# seasonally adjusted = observed - seasonal
value_sa = season_adjust
) %>%
as_tibble()
df_msas2 <- df_msas2 %>%
mutate(date = yearmonth(as.Date(date))) %>%
left_join(df_stl %>% select(msa_fips, date, value_sa),
by = c("msa_fips", "date"))
df_msas2 <- df_msas2 %>%
mutate(date = as.Date(date))
ggplot(df_msas2, aes(x = date, y = value_sa, group = msa_fips)) +
# background: all msas in grey
geom_line(color = "grey80", alpha = 0.4) +
# highlight: college towns in black
geom_line(
data = df_msas2 %>% dplyr::filter(CTind == 1),
color = "black",
alpha = 0.9,
linewidth  = 0.6
) +
labs(
x = "Date",
y = "Unemployment rate",
title = "Unemployment time series: all msas (grey) vs college towns (black)"
) +
theme_minimal()
# 1. Summarise by date and college_town
df_summary <- df_msas2 %>%
group_by(date, CTind) %>%
summarise(
p25 = quantile(value_sa, 0.25, na.rm = TRUE),
p50 = quantile(value_sa, 0.50, na.rm = TRUE),
p75 = quantile(value_sa, 0.75, na.rm = TRUE),
.groups = "drop"
) %>%
mutate(
CTind = factor(
CTind,
levels = c(0, 1),
labels = c("Non-college MSAs", "College-town MSAs")
)
)
# 2. Plot: ribbon = IQR, line = median
g1msa <- ggplot(df_summary,
aes(x = date)) +
geom_ribbon(aes(ymin = p25, ymax = p75,
color = CTind,
fill  = CTind),
alpha = 0.20,
color = NA) +
geom_line(aes(y = p50,linetype = CTind,color = CTind),
size = 1) +
scale_linetype_manual(values = c("dotted","solid"),
labels=c('Non-college MSAs', 'College-town MSAs'))+
labs(
x = "Date",
y = "Unemployment rate",
color = "",
fill  = "",linetype="",
#title = "Unemployment in college vs non-college counties",
subtitle = "Median (line) with 25th–75th percentiles shaded"
) +
theme_bw(base_size = 16)+theme(legend.position=c(.2,.75))+
labs(x="")+
scale_x_date(date_breaks = "4 years",date_labels = "%Y")
ggsave(filename = "output/g1msa.png",g1msa,scale=1,units = "cm",width = 20,height=15)
recessdf <- read_excel("data/macro/USRECM.xlsx",sheet=2) %>%
mutate(date = as.Date(date,format="%Y-%m-%d"))
df_msas2 <- df_msas2 %>% merge(recessdf,by="date",all.x = T) %>%
mutate(month_fe = factor(format(date, "%m")))
library(fixest)
did_mod <- feols(
value_sa ~ CTind * USRECM | msa_fips + date,
cluster = ~ msa_fips,
data = df_msas2 %>% dplyr::filter(year<2020)
)
summary(did_mod)
# Event
# Identify recession start months (from peak→trough indicator)
df2 <- df_msas2 %>%
mutate(
# ensure Date class; your format is "%Y-%m-%d"
date = as.Date(date, format = "%Y-%m-%d")
)
# Create a global time index t = 1, 2, 3, ... for each unique date
time_index <- df2 %>%
distinct(date) %>%
arrange(date) %>%
mutate(t = row_number())
# Join back to your main data
df2 <- df2 %>%
left_join(time_index, by = "date") %>%
arrange(msa_fips, date)
# Recession info by date (USRECM should be same for all counties each date)
rec_info <- df2 %>%
distinct(date, t, USRECM) %>%
arrange(t)
# A recession starts when USRECM goes from 0 -> 1
rec_info <- rec_info %>%
mutate(rec_start = ifelse(USRECM == 1 & dplyr::lag(USRECM, default = 0) == 0, 1, 0))
# Vector of t indices where recessions start
rec_start_t <- rec_info %>%
filter(rec_start == 1) %>%
pull(t)
rec_start_t
if (length(rec_start_t) == 0) {
stop("No recession starts found (USRECM never goes 0 -> 1).")
}
# Function that gives distance (in periods) to nearest recession start
closest_rel_time <- function(t, rec_starts) {
# rec_starts is the vector rec_start_t
diffs <- t - rec_starts
diffs[which.min(abs(diffs))]
}
# Compute rel_time for each row
df2$rel_time <- vapply(df2$t, closest_rel_time, integer(1L),
rec_starts = rec_start_t)
# Trim / bin the event window and pick a valid reference period
min_k <- -24
max_k <-  24
df2 <- df2 %>%
mutate(
rel_group = case_when(
rel_time < min_k ~ min_k,
rel_time > max_k ~ max_k,
TRUE ~ rel_time
)
)
# Check what values you actually have
sort(unique(df2$rel_group))
# last pre-recession event period present (e.g. -1, -2, etc.)
base_period <- max(df2$rel_group[df2$rel_group < 0], na.rm = TRUE)
base_period
# Run the event-study regression (fixest)
event_est <- feols(
value_sa ~ i(rel_group, CTind, ref = base_period) | msa_fips + t,
cluster = ~ msa_fips,
data = df2
)
summary(event_est)
g2msa_all <- ggiplot(event_est)+
labs(
#title = "Event Study: Effect of Recessions on Unemployment in College Towns",
title="",subtitle = "Estimation by MSAs",
x = "Periods relative to recession start",
y = "Effect on unemployment rate (percentage points)")+theme_bw(base_size = 16)
ggsave(filename = "output/g2msa_all.png",g2msa_all,scale=1,units = "cm",width = 20,height=15)
# Run the event-study regression (fixest)
event_est <- feols(
value_sa ~ i(rel_group, CTind, ref = base_period) | msa_fips + t,
cluster = ~ msa_fips,
data = df2 %>% dplyr::filter(year<2020)
)
summary(event_est)
g2msa_pre <- ggiplot(event_est)+
labs(
#title = "Event Study: Effect of Recessions on Unemployment in College Towns",
title="",subtitle = "Estimation by MSAs",
x = "Periods relative to recession start",
y = "Effect on unemployment rate (percentage points)")+theme_bw(base_size = 16)
ggsave(filename = "output/g2msa.png",g2msa_pre,scale=1,units = "cm",width = 20,height=15)
ggsave(filename = "output/g2msa_pre.png",g2msa_pre,scale=1,units = "cm",width = 20,height=15)
